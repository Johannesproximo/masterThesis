{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4486e087",
   "metadata": {},
   "source": [
    "# Notebook overview\n",
    "Computes pairwise cosine distance matrices between image embeddings for different dataset splits and saves the results.\n",
    "\n",
    "- Loads .pt embeddings via a CustomDataset and DataLoader\n",
    "- Normalizes embeddings (L2) and computes cosine distances in batches using sklearn.pairwise_distances\n",
    "- Saves distance matrices (.npy) and records calculation durations\n",
    "\n",
    "The notebook was exported as a Python script and run in a console using Tmux to execute it. The notebook was used for both origin and resized dataset just adapte the paths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad79b46",
   "metadata": {},
   "source": [
    "# Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25932f1c",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bfb1051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "torch.cuda.empty_cache()  # GPU-Cache clear\n",
    "torch.cuda.reset_peak_memory_stats()  # Reset statistics\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3903118c",
   "metadata": {},
   "source": [
    "### Load Paths - df_dir_path, embedding_dir_path, result_dir_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88d37254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df Folder\n",
    "DF_DIR_PATH = r'/home/jleick/masterArbeitProjekt/final_release/data/datasets/created'\n",
    "df_dir_path = Path(DF_DIR_PATH)\n",
    "if not df_dir_path.exists():\n",
    "    raise FileNotFoundError(f\"File does not exist: {DF_DIR_PATH}\")\n",
    "\n",
    "# Embeddings Folder\n",
    "HIGH_EMBEDDING_DIR_PATH = r'/home/jleick/masterArbeitProjekt/final_release/data/embeddings/adapted/resized/high'\n",
    "high_embedding_dir_path = Path(HIGH_EMBEDDING_DIR_PATH)\n",
    "if not high_embedding_dir_path.exists():\n",
    "    raise FileNotFoundError(f\"Folder does not exist: {HIGH_EMBEDDING_DIR_PATH}\")\n",
    "\n",
    "LOW_EMBEDDING_DIR_PATH = r'/home/jleick/masterArbeitProjekt/final_release/data/embeddings/adapted/resized/low'\n",
    "low_embedding_dir_path = Path(LOW_EMBEDDING_DIR_PATH)\n",
    "if not low_embedding_dir_path.exists():\n",
    "    raise FileNotFoundError(f\"Folder does not exist: {LOW_EMBEDDING_DIR_PATH}\")\n",
    "\n",
    "# Results Folder\n",
    "RESULT_DIR_PATH = r'/home/jleick/masterArbeitProjekt/final_release/models/knn/resized/model'\n",
    "result_dir_path = Path(RESULT_DIR_PATH)\n",
    "if not result_dir_path.exists():\n",
    "    raise FileNotFoundError(f\"Folder does not exist: {RESULT_DIR_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fcfcd0",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb336f0",
   "metadata": {},
   "source": [
    "### Function - CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d397b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset): # copy and refactored from CustomDatasetFineGrain Class availible in other files\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, embedding_dir_path: Path, column_name_tensor: str):\n",
    "        self.embedding_dir_path = embedding_dir_path\n",
    "        self.df_reduced = df[[column_name_tensor]].copy() # create dataFrame with relevant columns\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_reduced)\n",
    "\n",
    "    def __getitem__(self, item: int):\n",
    "        image_file_path = self.df_reduced.iloc[item, 0]\n",
    "        tensor_file_path = Path(image_file_path).with_suffix('.pt')\n",
    "        absolute_path = self.embedding_dir_path / tensor_file_path\n",
    "        tensor = torch.load( absolute_path , weights_only=True, map_location='cpu')\n",
    "        return tensor.squeeze() # squeeze to remove the first dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cdaf24",
   "metadata": {},
   "source": [
    "### Function - fill_distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45e543de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_distance_matrix( dataloader_x:DataLoader, dataloader_y:DataLoader, distance_matrix: np.ndarray) -> tuple[np.ndarray, datetime]:\n",
    "    start_time = datetime.now()\n",
    "    scaler = Normalizer(norm='l2')\n",
    "\n",
    "    row_count = 0\n",
    "    for embedding_batch_x in dataloader_x:\n",
    "        embedding_batch_x_scaled = scaler.transform(embedding_batch_x.detach().numpy())\n",
    "        len(embedding_batch_x_scaled)\n",
    "        col_count = 0\n",
    "        for embedding_batch_y in dataloader_y:\n",
    "            embedding_batch_y_scaled = scaler.transform(embedding_batch_y.detach().numpy())\n",
    "            len(embedding_batch_y_scaled)\n",
    "            distance_batch = pairwise_distances(embedding_batch_x_scaled, embedding_batch_y_scaled,  metric='cosine', n_jobs=-1)\n",
    "\n",
    "            row_batch_y = distance_batch.shape[0]\n",
    "            col_batch_y =  distance_batch.shape[1]\n",
    "            \n",
    "            distance_matrix[\n",
    "                row_count: row_count + row_batch_y,\n",
    "                col_count: col_count + col_batch_y\n",
    "                ] = distance_batch\n",
    "\n",
    "            col_count += col_batch_y\n",
    "            print(f\"> {col_count} columns in batch_y calculated\")\n",
    "\n",
    "        row_batch_x = embedding_batch_x_scaled.shape[0]\n",
    "        row_count += row_batch_x\n",
    "\n",
    "        batch_time_x = datetime.now()\n",
    "        duration_batch_time_x = batch_time_x - start_time\n",
    "        print(f\">>> {row_count} rows in batch_y calculated in time: {duration_batch_time_x}\")\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    durcation_time = end_time - start_time\n",
    "    return distance_matrix, durcation_time\n",
    "\n",
    "# Optimize calculation: symmetric matrix - upper triangular matrix calculation sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb98edc",
   "metadata": {},
   "source": [
    "### Function - calculate_distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6b9bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_matrix( x_dataset_path: Path, col_name: str, embedding_dir_path: Path, save_path: Path):\n",
    "    x_df = pd.read_csv( x_dataset_path , index_col=False, usecols=[col_name]) # nrows=10\n",
    "    y_df = pd.read_csv( df_dir_path / 'high_id_train.csv', index_col=False, usecols=['image_path']) # nrows=10\n",
    "    print(\"dfs loaded\")\n",
    "\n",
    "    x_dataset = CustomDataset(x_df, embedding_dir_path, col_name)\n",
    "    y_dataset = CustomDataset(y_df, high_embedding_dir_path, 'image_path')\n",
    "    print(\"datasets created\")\n",
    "\n",
    "    x_dataloader = DataLoader(x_dataset, batch_size=4096, shuffle=False) #batch_size=4096\n",
    "    y_dataloader = DataLoader(y_dataset, batch_size=1024, shuffle=False) #batch_size=1024\n",
    "    print(\"dataloader created\")\n",
    "\n",
    "    nr_rows_df = len(x_df)\n",
    "    nr_cols_df = len(y_df)\n",
    "    distance_matrix = np.empty((nr_rows_df, nr_cols_df), dtype=np.float32)\n",
    "    print(f\"empty matrix created: {nr_rows_df}, {nr_cols_df}\")\n",
    "\n",
    "    distance_matrix_calculated, duration_time = fill_distance_matrix( x_dataloader, y_dataloader, distance_matrix )\n",
    "    print(\"distance matrix calculated\")\n",
    "\n",
    "    if nr_rows_df == nr_cols_df:\n",
    "        np.fill_diagonal(distance_matrix_calculated, 0.0) # Correcting rounding errors on the diagonal\n",
    "        print(\"Diagonal elements of the matrix set to 0\")\n",
    "\n",
    "    # save distance_matrix\n",
    "    np.save( save_path , distance_matrix_calculated)\n",
    "\n",
    "    # Save calculation time\n",
    "    with open( save_path.parent / f\"{save_path.name}_calculation_time.txt\" , \"w\") as f:\n",
    "        f.write(str(duration_time))\n",
    "    print(f\"results saved at: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f270bf49",
   "metadata": {},
   "source": [
    "# Apply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb05806d",
   "metadata": {},
   "source": [
    "### Apply - calculate_distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a4aafbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfs loaded\n",
      "datasets created\n",
      "dataloader created\n",
      "empty matrix created: 10, 10\n",
      "> 10 columns in batch_y calculated\n",
      ">>> 10 rows in batch_y calculated in time: 0:00:00.036897\n",
      "distance matrix calculated\n",
      "Diagonal elements of the matrix set to 0\n",
      "results saved at: /home/jleick/masterArbeitProjekt/final_release/models/knn/resized/model/distance_matrix_high_id_val.npy\n",
      "dfs loaded\n",
      "datasets created\n",
      "dataloader created\n",
      "empty matrix created: 10, 10\n",
      "> 10 columns in batch_y calculated\n",
      ">>> 10 rows in batch_y calculated in time: 0:00:00.032817\n",
      "distance matrix calculated\n",
      "Diagonal elements of the matrix set to 0\n",
      "results saved at: /home/jleick/masterArbeitProjekt/final_release/models/knn/resized/model/distance_matrix_high_id_test.npy\n",
      "dfs loaded\n",
      "datasets created\n",
      "dataloader created\n",
      "empty matrix created: 10, 10\n",
      "> 10 columns in batch_y calculated\n",
      ">>> 10 rows in batch_y calculated in time: 0:00:00.035508\n",
      "distance matrix calculated\n",
      "Diagonal elements of the matrix set to 0\n",
      "results saved at: /home/jleick/masterArbeitProjekt/final_release/models/knn/resized/model/distance_matrix_high_ood_test.npy\n",
      "dfs loaded\n",
      "datasets created\n",
      "dataloader created\n",
      "empty matrix created: 10, 10\n",
      "> 10 columns in batch_y calculated\n",
      ">>> 10 rows in batch_y calculated in time: 0:00:01.543287\n",
      "distance matrix calculated\n",
      "Diagonal elements of the matrix set to 0\n",
      "results saved at: /home/jleick/masterArbeitProjekt/final_release/models/knn/resized/model/distance_matrix_low_id_test.npy\n",
      "dfs loaded\n",
      "datasets created\n",
      "dataloader created\n",
      "empty matrix created: 10, 10\n",
      "> 10 columns in batch_y calculated\n",
      ">>> 10 rows in batch_y calculated in time: 0:00:01.625153\n",
      "distance matrix calculated\n",
      "Diagonal elements of the matrix set to 0\n",
      "results saved at: /home/jleick/masterArbeitProjekt/final_release/models/knn/resized/model/distance_matrix_low_ood_test.npy\n"
     ]
    }
   ],
   "source": [
    "# calculate_distance_matrix( df_dir_path / 'high_id_train.csv', 'image_path', result_dir_path / \"distance_matrix_high_id_train.npy\")\n",
    "calculate_distance_matrix( df_dir_path / 'high_id_val.csv', 'image_path', high_embedding_dir_path, result_dir_path / \"distance_matrix_high_id_val.npy\")\n",
    "\n",
    "calculate_distance_matrix( df_dir_path / 'high_id_test.csv', 'image_path', high_embedding_dir_path, result_dir_path / \"distance_matrix_high_id_test.npy\")\n",
    "calculate_distance_matrix( df_dir_path / 'high_ood_test.csv', 'image_path', high_embedding_dir_path, result_dir_path / \"distance_matrix_high_ood_test.npy\")\n",
    "\n",
    "calculate_distance_matrix( df_dir_path / 'low_id_test.csv', 'identifier', low_embedding_dir_path, result_dir_path / \"distance_matrix_low_id_test.npy\")\n",
    "calculate_distance_matrix( df_dir_path / 'low_ood_test.csv', 'identifier', low_embedding_dir_path, result_dir_path / \"distance_matrix_low_ood_test.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69417569",
   "metadata": {},
   "source": [
    "# Review Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b62e67b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sympy as sp\n",
    "\n",
    "# M = sp.Matrix(distance_matrix[0:100,0:100])\n",
    "# M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5874fdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_0 = train_dataset[0][0].cpu().detach().numpy().reshape(1, -1)\n",
    "# embedding_0_scaled = scaler.transform(embedding_0)\n",
    "# embedding_1 = train_dataset[3][0].cpu().detach().numpy().reshape(1, -1)\n",
    "# embedding_1_scaled = scaler.transform(embedding_1)\n",
    "\n",
    "# pairwise_distances( embedding_0_scaled, embedding_1_scaled, metric = 'cosine')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterArbeit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
