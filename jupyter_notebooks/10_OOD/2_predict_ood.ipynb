{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f11e8092",
   "metadata": {},
   "source": [
    "# Notebook overview\n",
    "\n",
    "Predicts Out-of-Distribution (OOD) status for all test sets by applying various thresholds to k-NN prediction results.\n",
    "\n",
    "- Loads prediction data: Imports results containing k-distances and predicted labels.\n",
    "- Threshold Application for OOD Classification: Applies three distinct OOD threshold strategies over_alle_species, for_each_species, and in_each_species to classify examples as \"In-Distribution\" or \"Out-of-Distribution\" based on their distance.\n",
    "- Class-specific thresholds are derived based on predictions from different classifiers (MLP and k-NN).\n",
    "- Saves the updated prediction DataFrames, including OOD flags.\n",
    "\n",
    "The notebook was used for both datasets(original and resized) just adapte the paths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0e81cc",
   "metadata": {},
   "source": [
    "# Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f4b56e",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f4c38a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import ast\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed51354",
   "metadata": {},
   "source": [
    "### Path - prediction_dir_path, result_dir_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9be68fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The paths for the original and resized data must be adjusted for calculation of original or resized ood Prediction (Replace “origin” with “resized” and vice versa).\n",
    "\n",
    "### prediction folder to load df (includes distances to predict ood)\n",
    "PREDICTION_DIR_PATH = r'/home/stud/jleick/masterArbeitProjekt/final_release/models/knn/resized/prediction'\n",
    "prediction_dir_path = Path(PREDICTION_DIR_PATH)\n",
    "if not prediction_dir_path.exists():\n",
    "    raise FileNotFoundError(f\"Folder does not exist: {PREDICTION_DIR_PATH}\")\n",
    "\n",
    "### prediction folder to load df\n",
    "MLP_PREDICTION_DIR_PATH = r'/home/stud/jleick/masterArbeitProjekt/final_release/models/mlp/resized/prediction'\n",
    "mlp_prediction_dir_path = Path(MLP_PREDICTION_DIR_PATH)\n",
    "if not mlp_prediction_dir_path.exists():\n",
    "    raise FileNotFoundError(f\"Folder does not exist: {MLP_PREDICTION_DIR_PATH}\")\n",
    "\n",
    "### threshold Folder to load df\n",
    "THRESHOLD_DIR_PATH = r'/home/stud/jleick/masterArbeitProjekt/final_release/models/ood/thresholds/resized'\n",
    "threshold_dir_path = Path(THRESHOLD_DIR_PATH)\n",
    "if not threshold_dir_path.exists():\n",
    "    raise FileNotFoundError(f\"Folder does not exist: {THRESHOLD_DIR_PATH}\")\n",
    "\n",
    "### Folder to save results\n",
    "RESULT_DIR_PATH = r'/home/stud/jleick/masterArbeitProjekt/final_release/models/ood/predictions/resized'\n",
    "result_dir_path = Path(RESULT_DIR_PATH)\n",
    "if not result_dir_path.exists():\n",
    "    raise FileNotFoundError(f\"Folder does not exist: {RESULT_DIR_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2bed72",
   "metadata": {},
   "source": [
    "### Load dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b8a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The paths must be adjusted for high and low datasets to k_13.csv and k_10.csv, respectively.\n",
    "\n",
    "# for ood prediction and for knn species prediction for ood prediction on species level\n",
    "high_id_test_prediction_df = pd.read_csv( prediction_dir_path / 'high_id_test_prediction_k_13.csv', index_col=False, converters={\"k_distances\": ast.literal_eval})\n",
    "high_ood_test_prediction_df = pd.read_csv( prediction_dir_path / 'high_ood_test_prediction_k_13.csv', index_col=False, converters={\"k_distances\": ast.literal_eval})\n",
    "\n",
    "low_id_test_prediction_df = pd.read_csv( prediction_dir_path / 'low_id_test_prediction_k_13.csv', index_col=False, converters={\"k_distances\": ast.literal_eval})\n",
    "low_ood_test_prediction_df = pd.read_csv( prediction_dir_path / 'low_ood_test_prediction_k_13.csv', index_col=False, converters={\"k_distances\": ast.literal_eval})\n",
    "\n",
    "# for mlp species prediction for ood prediction on species level\n",
    "mlp_high_id_test_prediction_df = pd.read_csv( mlp_prediction_dir_path / 'high_id_test_prediction.csv', index_col=False, converters={\"k_distances\": ast.literal_eval})\n",
    "mlp_high_ood_test_prediction_df = pd.read_csv( mlp_prediction_dir_path / 'high_ood_test_prediction.csv', index_col=False, converters={\"k_distances\": ast.literal_eval})\n",
    "\n",
    "mlp_low_id_test_prediction_df = pd.read_csv( mlp_prediction_dir_path / 'low_id_test_prediction.csv', index_col=False, converters={\"k_distances\": ast.literal_eval})\n",
    "mlp_low_ood_test_prediction_df = pd.read_csv( mlp_prediction_dir_path / 'low_ood_test_prediction.csv', index_col=False, converters={\"k_distances\": ast.literal_eval})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd1e171",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab80d8",
   "metadata": {},
   "source": [
    "### Function - merge_knn_to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4929e267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_knn_to_df( main_df, to_merge_df):\n",
    "    prepare_to_merge_df = to_merge_df.drop(['label','prediction'], axis=1)\n",
    "    merged_df = main_df.merge(prepare_to_merge_df, how='left', on='image_path')\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fea5761",
   "metadata": {},
   "source": [
    "### Functions - save_thresholds, load_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "27cb2316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save resultes\n",
    "def save_thresholds(file, save_path):\n",
    "    try:\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            pickle.dump(file, f)\n",
    "        print(f\"thresholds saved succesfully: {save_path} \")\n",
    "    except (IOError, pickle.PickleError) as e:\n",
    "        print(f\"error occure while save trasholds: {e}\")\n",
    "\n",
    "# open resultes\n",
    "def load_thresholds(load_path):\n",
    "    try:\n",
    "        with open(load_path, \"rb\") as f:\n",
    "            threshold_dict = pickle.load(f)\n",
    "        print(\"thresholds loaded succesfully\")\n",
    "        return threshold_dict\n",
    "    except (IOError, pickle.PickleError, EOFError) as e:\n",
    "        print(f\"error occure while loaded trasholds: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d208e5f",
   "metadata": {},
   "source": [
    "### Functions - predict_ood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0cf2f26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ood( df:pd.DataFrame, thresholds: dict) -> pd.DataFrame:\n",
    "    df_copied = df.copy()\n",
    "\n",
    "    distances = np.stack(df_copied['k_distances'].values)\n",
    "    last_distances = distances[:,-1]\n",
    "\n",
    "    for percentile, threshold in thresholds.items():\n",
    "        is_ood = last_distances > threshold \n",
    "        df_copied[f'ood_{percentile}'] = np.where( is_ood, -1, df_copied['prediction'])\n",
    "    \n",
    "    return df_copied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1857a01",
   "metadata": {},
   "source": [
    "### Function - get_thresholds_of_percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0ff4e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thresholds_of_percentile(thresholds_dict:dict, percentile: float):\n",
    "    result_dict = {}\n",
    "\n",
    "    for label, thresholds in thresholds_dict.items():\n",
    "        result_dict[label] = thresholds[percentile]\n",
    "    \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c51d95c",
   "metadata": {},
   "source": [
    "### Function - predict_ood_for_species (on largest distance anyway which class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008afa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ood_for_species(df:pd.DataFrame, thresholds_dict: dict, percentiles:float):\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    for percentile in percentiles:\n",
    "        distances = df_copy['k_distances']\n",
    "        last_distances = np.stack( distances.values )[:,-1]\n",
    "\n",
    "        threshold_percentile_dict = get_thresholds_of_percentile( thresholds_dict, percentile )\n",
    "        thresholds = df_copy['prediction'].map( threshold_percentile_dict )\n",
    "\n",
    "        is_ood = last_distances > thresholds\n",
    "        df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cee82c",
   "metadata": {},
   "source": [
    "### Function - predict_ood_for_species (on largest distance on exampel of predicted class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0c2ab943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_last_label_distance(k_labels:pd.Series, k_distances:pd.Series, prediction:int) -> float:\n",
    "#     for i in range(len(k_labels) - 1, -1, -1):  # rückwärts suchen\n",
    "#         if k_labels[i] == prediction:\n",
    "#             return k_distances[i]\n",
    "#     return k_distances[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "abaf0c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_ood_for_species(df: pd.DataFrame, thresholds_dict: dict, percentiles: list):\n",
    "#     df_copy = df.copy()\n",
    "\n",
    "#     last_distances = df_copy.apply(\n",
    "#         lambda row: get_last_label_distance(\n",
    "#             row['k_image_labels'], \n",
    "#             row['k_distances'], \n",
    "#             row['prediction']\n",
    "#         ), \n",
    "#         axis=1\n",
    "#     ).values\n",
    "    \n",
    "#     for percentile in percentiles:\n",
    "#         threshold_percentile_dict = get_thresholds_of_percentile(thresholds_dict, percentile)\n",
    "#         thresholds = df_copy['prediction'].map( threshold_percentile_dict ).values\n",
    "\n",
    "#         is_ood = last_distances > thresholds\n",
    "#         df_copy[f'ood_{percentile}'] = np.where(is_ood, -1, df_copy['prediction'])\n",
    "    \n",
    "#     return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5499c80",
   "metadata": {},
   "source": [
    "### Function - run_prediction_over_all_exampels_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "33adfd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prediction_over_all_exampels_thresholds( threshold_load_path: Path, prediction_save_path: Path, high_id_test_prediction: pd.DataFrame, high_ood_test_prediction: pd.DataFrame, low_id_test_prediction: pd.DataFrame, low_ood_test_prediction: pd.DataFrame):\n",
    "    thresholds_dict = load_thresholds( threshold_load_path )\n",
    "\n",
    "    # predict ood\n",
    "    pred_ood_for_high_id_test = predict_ood( high_id_test_prediction, thresholds_dict )\n",
    "    pred_ood_for_high_ood_test = predict_ood( high_ood_test_prediction, thresholds_dict )\n",
    "    \n",
    "    pred_ood_for_low_id_test = predict_ood( low_id_test_prediction, thresholds_dict )\n",
    "    pred_ood_for_low_ood_test = predict_ood( low_ood_test_prediction, thresholds_dict )\n",
    "\n",
    "    # save results\n",
    "    pred_ood_for_high_id_test.to_csv( prediction_save_path / 'high_id_test_prediction_ood.csv', index=False)\n",
    "    pred_ood_for_high_ood_test.to_csv( prediction_save_path / 'high_ood_test_prediction_ood.csv', index=False)\n",
    "\n",
    "    pred_ood_for_low_id_test.to_csv( prediction_save_path / 'low_id_test_prediction_ood.csv', index=False)\n",
    "    pred_ood_for_low_ood_test.to_csv( prediction_save_path / 'low_ood_test_prediction_ood.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c7a48c",
   "metadata": {},
   "source": [
    "### Function - run_prediction_for_species_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "478ebd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run_prediction_for_species_thresholds( threshold_load_path: Path, prediction_save_path: Path, high_id_test_prediction: pd.DataFrame, high_ood_test_prediction: pd.DataFrame, low_id_test_prediction: pd.DataFrame, low_ood_test_prediction: pd.DataFrame, percentiles: np.array):\n",
    "    thresholds_dict = load_thresholds( threshold_load_path )\n",
    "\n",
    "    # predict ood\n",
    "    pred_ood_for_high_id_test = predict_ood_for_species(high_id_test_prediction, thresholds_dict, percentiles)\n",
    "    pred_ood_for_high_ood_test = predict_ood_for_species(high_ood_test_prediction, thresholds_dict, percentiles)\n",
    "\n",
    "    pred_ood_for_low_id_test = predict_ood_for_species(low_id_test_prediction, thresholds_dict, percentiles)\n",
    "    pred_ood_for_low_ood_test = predict_ood_for_species(low_ood_test_prediction, thresholds_dict, percentiles)\n",
    "\n",
    "    # save results\n",
    "    pred_ood_for_high_id_test.to_csv( prediction_save_path / 'high_id_test_prediction_ood.csv', index=False)\n",
    "    pred_ood_for_high_ood_test.to_csv( prediction_save_path / 'high_ood_test_prediction_ood.csv', index=False)\n",
    "\n",
    "    pred_ood_for_low_id_test.to_csv( prediction_save_path / 'low_id_test_prediction_ood.csv', index=False)\n",
    "    pred_ood_for_low_ood_test.to_csv( prediction_save_path / 'low_ood_test_prediction_ood.csv', index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041367c2",
   "metadata": {},
   "source": [
    "# Apply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2120b6a9",
   "metadata": {},
   "source": [
    "# Apply - over_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0f55e412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresholds loaded succesfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_510826/2184056091.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copied[f'ood_{percentile}'] = np.where( is_ood, -1, df_copied['prediction'])\n",
      "/tmp/ipykernel_510826/2184056091.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copied[f'ood_{percentile}'] = np.where( is_ood, -1, df_copied['prediction'])\n",
      "/tmp/ipykernel_510826/2184056091.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copied[f'ood_{percentile}'] = np.where( is_ood, -1, df_copied['prediction'])\n",
      "/tmp/ipykernel_510826/2184056091.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copied[f'ood_{percentile}'] = np.where( is_ood, -1, df_copied['prediction'])\n",
      "/tmp/ipykernel_510826/2184056091.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copied[f'ood_{percentile}'] = np.where( is_ood, -1, df_copied['prediction'])\n",
      "/tmp/ipykernel_510826/2184056091.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copied[f'ood_{percentile}'] = np.where( is_ood, -1, df_copied['prediction'])\n",
      "/tmp/ipykernel_510826/2184056091.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copied[f'ood_{percentile}'] = np.where( is_ood, -1, df_copied['prediction'])\n",
      "/tmp/ipykernel_510826/2184056091.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copied[f'ood_{percentile}'] = np.where( is_ood, -1, df_copied['prediction'])\n",
      "/tmp/ipykernel_510826/2184056091.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copied[f'ood_{percentile}'] = np.where( is_ood, -1, df_copied['prediction'])\n",
      "/tmp/ipykernel_510826/2184056091.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copied[f'ood_{percentile}'] = np.where( is_ood, -1, df_copied['prediction'])\n",
      "/tmp/ipykernel_510826/2184056091.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copied[f'ood_{percentile}'] = np.where( is_ood, -1, df_copied['prediction'])\n",
      "/tmp/ipykernel_510826/2184056091.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copied[f'ood_{percentile}'] = np.where( is_ood, -1, df_copied['prediction'])\n"
     ]
    }
   ],
   "source": [
    "run_prediction_over_all_exampels_thresholds(\n",
    "    threshold_dir_path / 'thresholds_over_all_examples.pkl',\n",
    "    result_dir_path / 'over_all_examples',\n",
    "    high_id_test_prediction_df,\n",
    "    high_ood_test_prediction_df,\n",
    "    low_id_test_prediction_df,\n",
    "    low_ood_test_prediction_df\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba44eaa1",
   "metadata": {},
   "source": [
    "# knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "00dc22d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = np.arange(0.0,1.001,0.01)\n",
    "percentiles = np.round(percentiles, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e846f30d",
   "metadata": {},
   "source": [
    "### Apply - for_each_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4e1e952c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresholds loaded succesfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n"
     ]
    }
   ],
   "source": [
    "run_prediction_for_species_thresholds(\n",
    "    threshold_dir_path / 'thresholds_for_each_species.pkl',\n",
    "    result_dir_path / 'knn/for_each_species',\n",
    "    high_id_test_prediction_df,\n",
    "    high_ood_test_prediction_df,\n",
    "    low_id_test_prediction_df,\n",
    "    low_ood_test_prediction_df,\n",
    "    percentiles\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3f8386",
   "metadata": {},
   "source": [
    "### Apply - in_each_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "57bbc418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresholds loaded succesfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n"
     ]
    }
   ],
   "source": [
    "run_prediction_for_species_thresholds(\n",
    "    threshold_dir_path / 'thresholds_in_each_species.pkl',\n",
    "    result_dir_path / 'knn/in_each_species',\n",
    "    high_id_test_prediction_df,\n",
    "    high_ood_test_prediction_df,\n",
    "    low_id_test_prediction_df,\n",
    "    low_ood_test_prediction_df,\n",
    "    percentiles\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1d98be",
   "metadata": {},
   "source": [
    "# mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5003ab",
   "metadata": {},
   "source": [
    "### merge - mlp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d7225214",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_high_id_test_prediction_df_merged = merge_knn_to_df(mlp_high_id_test_prediction_df, high_id_test_prediction_df)\n",
    "mlp_high_ood_test_prediction_df_merged = merge_knn_to_df(mlp_high_ood_test_prediction_df, high_ood_test_prediction_df)\n",
    "\n",
    "mlp_low_id_test_prediction_df_merged = merge_knn_to_df(mlp_low_id_test_prediction_df, low_id_test_prediction_df)\n",
    "mlp_low_ood_test_prediction_df_merged = merge_knn_to_df(mlp_low_ood_test_prediction_df, low_ood_test_prediction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1b119d",
   "metadata": {},
   "source": [
    "### Apply - for_each_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1cb12c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresholds loaded succesfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n"
     ]
    }
   ],
   "source": [
    "run_prediction_for_species_thresholds(\n",
    "    threshold_dir_path / 'thresholds_for_each_species.pkl',\n",
    "    result_dir_path / 'mlp/for_each_species',\n",
    "    mlp_high_id_test_prediction_df_merged,\n",
    "    mlp_high_ood_test_prediction_df_merged,\n",
    "    mlp_low_id_test_prediction_df_merged,\n",
    "    mlp_low_ood_test_prediction_df_merged,\n",
    "    percentiles\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb541e09",
   "metadata": {},
   "source": [
    "### Apply - in_each_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0eed3f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresholds loaded succesfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n",
      "/tmp/ipykernel_510826/2039493002.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_copy[f'ood_{percentile}'] = np.where( is_ood, -1, df_copy['prediction'] )\n"
     ]
    }
   ],
   "source": [
    "run_prediction_for_species_thresholds(\n",
    "    threshold_dir_path / 'thresholds_in_each_species.pkl',\n",
    "    result_dir_path / 'mlp/in_each_species',\n",
    "    mlp_high_id_test_prediction_df_merged,\n",
    "    mlp_high_ood_test_prediction_df_merged,\n",
    "    mlp_low_id_test_prediction_df_merged,\n",
    "    mlp_low_ood_test_prediction_df_merged,\n",
    "    percentiles\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterArbeit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
